version: "3.8"

services:
  ollama:
    image: ollama/ollama:latest  # Official Ollama Docker image
    container_name: ollama_server
    volumes:
      - ./ollama/ollama:/root/.ollama
      - ./entrypoint.sh:/entrypoint.sh
    ports:
      - "11434:11434"
    restart: always
    entrypoint: ["sh", "-c", "ollama pull mistral"]

  flask_app:
    build: .
    container_name: flask_microservice
    ports:
      - "4000:4000"
    depends_on:
      - ollama  # Ensure Ollama starts first
    environment:
      - OLLAMA_HOST=http://ollama:11434
    restart: always
    # Wait for Ollama to be fully up and running
    entrypoint: ["sh", "-c", "until nc -z -v -w30 ollama 11434; do echo 'Waiting for Ollama to start...'; sleep 5; done; python app.py"]
